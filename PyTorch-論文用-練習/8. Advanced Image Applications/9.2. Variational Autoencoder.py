'''
è‡ªç·¨ç¢¼å™¨(AutoEncoder)æ˜¯ä¸€ç¨®ç„¡ç›£ç£å­¸ç¿’çš„ç¥ç¶“ç¶²è·¯ï¼Œä¸»è¦ç”¨æ–¼æ•¸æ“šçš„é™ç¶­å’Œç‰¹å¾µå­¸ç¿’ã€‚
å‚³çµ±çš„è‡ªç·¨ç¢¼å™¨ç”±å…©éƒ¨åˆ†çµ„æˆï¼š
    ç·¨ç¢¼å™¨(Encoder)ï¼šå°‡è¼¸å…¥æ•¸æ“šå£“ç¸®æˆä½ç¶­åº¦çš„æ½›åœ¨è¡¨ç¤º (latent representation) (é«˜è½‰ä½)
    è§£ç¢¼å™¨(Decoder)ã€‚æ ¹æ“šé€™å€‹æ½›åœ¨è¡¨ç¤ºé‡å»ºè¼¸å…¥æ•¸æ“š(ä½è½‰é«˜)

å‚³çµ±è‡ªç·¨ç¢¼å™¨çš„æ½›åœ¨è¡¨ç¤º(é™ç¶­çµæœ)æ˜¯ç¢ºå®šæ€§çš„ï¼Œé€™å°è‡´å…¶åœ¨ç”Ÿæˆæ•¸æ“šæ™‚çš„èƒ½åŠ›æœ‰é™ã€‚
    ä¾‹å¦‚ï¼š è‹¥å¸Œæœ›ç”Ÿæˆæ–°æ•¸æ“šï¼Œã€å‚³çµ±è‡ªç·¨ç¢¼å™¨ç„¡æ³•æœ‰æ•ˆåœ°åœ¨æ½›åœ¨ç©ºé–“ä¸­é€²è¡Œæ’å€¼æˆ–éš¨æ©Ÿé‡‡æ¨£ã€‘ã€‚ç‚ºäº†è§£æ±ºé€™å€‹å•é¡Œï¼Œè®Šåˆ†è‡ªç·¨ç¢¼å™¨(VAE)æ‡‰é‹è€Œç”Ÿã€‚
        
        ã€è¨»ã€‘ï¼šæ½›åœ¨ç©ºé–“
        æ½›åœ¨ç©ºé–“(Latent Space)æŒ‡çš„æ˜¯ä¸€å€‹æŠ½è±¡çš„ã€ä½ç¶­åº¦çš„ç©ºé–“ï¼Œå®ƒç”¨ä¾†è¡¨ç¤ºæ•¸æ“šçš„æ ¸å¿ƒç‰¹å¾µæˆ–æœ¬è³ªã€‚åœ¨è‡ªç·¨ç¢¼å™¨æˆ–è®Šåˆ†è‡ªç·¨ç¢¼å™¨çš„æ¶æ§‹ä¸­ï¼Œæ½›åœ¨ç©ºé–“é€šå¸¸æ˜¯ç”±ç·¨ç¢¼å™¨(Encoder)å¾é«˜ç¶­çš„è¼¸å…¥æ•¸æ“š(å¦‚åœ–ç‰‡ã€è²éŸ³ã€æ–‡æœ¬)ä¸­å£“ç¸®è€Œä¾†çš„ä¸€çµ„ä½ç¶­åº¦çš„å‘é‡è¡¨ç¤ºã€‚
        é€™å€‹æ½›åœ¨ç©ºé–“åŒ…å«äº†æ•¸æ“šä¸­æœ€é—œéµçš„ä¿¡æ¯ï¼Œä½†å®ƒçš„ç¶­åº¦è¦é å°æ–¼åŸå§‹æ•¸æ“šçš„ç¶­åº¦ã€‚ä¾‹å¦‚ï¼Œä¸€å¼µ 28x28 çš„ç°åº¦åœ–åƒæœ‰ 784 å€‹åƒç´ é»ï¼Œä½†å®ƒå¯èƒ½å¯ä»¥å£“ç¸®æˆä¸€å€‹ 2 ç¶­æˆ– 3 ç¶­çš„æ½›åœ¨ç©ºé–“è¡¨ç¤ºã€‚é€™äº›ä½ç¶­å‘é‡èƒ½å¤ æ•æ‰åˆ°åœ–åƒä¸­æœ€é‡è¦çš„ç‰¹å¾µï¼Œå¿½ç•¥æ‰ä¸å¿…è¦çš„ç´°ç¯€ã€‚
            1. æ½›åœ¨ç©ºé–“æä¾›äº†ä¸€ç¨®å£“ç¸®é«˜ç¶­æ•¸æ“šçš„æ–¹æ³•ï¼Œä½¿å¾—æ•¸æ“šèƒ½å¤ åœ¨æ›´å°çš„ç©ºé–“ä¸­é€²è¡Œè¡¨ç¤ºã€‚
            2. æ½›åœ¨ç©ºé–“ä¸­ï¼Œå¯ä»¥é€šéè§£ç¢¼å™¨(Decoder)å°‡æ½›åœ¨ç©ºé–“ä¸­çš„é»è½‰åŒ–ç‚ºåŸå§‹æ•¸æ“šçš„é‡å»ºã€‚
            3. æ½›åœ¨ç©ºé–“æä¾›äº†ä¸€å€‹å¯ä»¥æ¢ç´¢çš„ç¯„åœï¼Œæˆ‘å€‘å¯ä»¥åœ¨æ½›åœ¨ç©ºé–“ä¸­é€²è¡Œæ’å€¼ï¼Œå³åœ¨å…©å€‹é»ä¹‹é–“æ‰¾åˆ°ä¸­é–“é»ï¼Œä¸¦é€šéè§£ç¢¼å™¨ç”Ÿæˆä¸€å€‹æ–°çš„æ•¸æ“šé»ã€‚é€™ä½¿å¾—æˆ‘å€‘å¯ä»¥åœ¨ä¸åŒé¡å‹çš„æ•¸æ“šä¹‹é–“é€²è¡Œå¹³æ»‘éæ¸¡ã€‚
        æ½›åœ¨ç©ºé–“èˆ‡åŸå§‹æ•¸æ“šç©ºé–“çš„æœ€å¤§å€åˆ¥åœ¨æ–¼ç¶­åº¦çš„ä¸åŒã€‚åŸå§‹ç©ºé–“é€šå¸¸æ˜¯é«˜ç¶­çš„ï¼Œå……æ»¿äº†å™ªè²å’Œå†—é¤˜ä¿¡æ¯ã€‚è€Œæ½›åœ¨ç©ºé–“å‰‡æ˜¯ä¸€å€‹ä½ç¶­ç©ºé–“ï¼Œå®ƒåªä¿ç•™äº†æ•¸æ“šçš„æœ€é—œéµç‰¹å¾µã€‚
            

        ã€è¨»ã€‘ï¼šæ½›åœ¨ç©ºé–“çš„ç¢ºå®šæ€§è¡¨ç¤º
        å‚³çµ±è‡ªç·¨ç¢¼å™¨çš„ç·¨ç¢¼å™¨å°‡è¼¸å…¥æ•¸æ“šå£“ç¸®æˆä¸€å€‹å›ºå®šçš„å‘é‡ï¼Œé€™å€‹å‘é‡æ˜¯ä¸€å€‹ç¢ºå®šæ€§çš„è¡¨ç¤ºã€‚ä¹Ÿå°±æ˜¯èªªï¼Œå°æ–¼æ¯ä¸€å€‹è¼¸å…¥æ•¸æ“šï¼Œç·¨ç¢¼å™¨éƒ½æœƒç”Ÿæˆä¸€å€‹å”¯ä¸€çš„æ½›åœ¨è¡¨ç¤ºã€‚é€™ç¨®ç¢ºå®šæ€§çš„è¡¨ç¤ºä½¿å¾—æ½›åœ¨ç©ºé–“ä¸­çš„å‘é‡åˆ†ä½ˆå¯èƒ½éå¸¸ä¸é€£çºŒï¼Œç”šè‡³å¯èƒ½å‡ºç¾ã€Œé›¢æ•£åŒ–ã€ç¾è±¡ã€‚
        ä¾‹å¦‚ï¼Œå‡è¨­æœ‰å…©å€‹è¼¸å…¥æ•¸æ“š X1 èˆ‡ X2ï¼Œç·¨ç¢¼å™¨å°‡å®ƒå€‘åˆ†åˆ¥æ˜ å°„åˆ°æ½›åœ¨ç©ºé–“ä¸­çš„å…©å€‹é» Z1 èˆ‡ Z2
        ç”±æ–¼é€™äº›é»æ˜¯ç¢ºå®šæ€§çš„ï¼Œæ½›åœ¨ç©ºé–“ä¸­å¯èƒ½å‡ºç¾é€™æ¨£çš„æƒ…æ³ï¼š Z1 èˆ‡ Z2 é›–ç„¶åœ¨æ•¸å­¸ä¸Šé å¾—å¾ˆè¿‘ï¼Œä½†å®ƒå€‘ä¹‹é–“çš„ç©ºé–“å¯èƒ½ä¸ä»£è¡¨çœŸå¯¦çš„æ•¸æ“šåˆ†ä½ˆã€‚

        
        ã€è¨»ã€‘ï¼šæ½›åœ¨ç©ºé–“ä¸­çš„æ’å€¼å•é¡Œ
        æ’å€¼çš„æ„æ€æ˜¯ï¼Œåœ¨å·²çŸ¥å…©å€‹é»ä¹‹é–“æ‰¾åˆ°ä¸€å€‹åˆç†çš„ä¸­é–“é»ã€‚å‡è¨­æƒ³è¦åœ¨æ½›åœ¨ç©ºé–“ä¸­æ’å€¼ï¼Œä¾†ç”Ÿæˆä¸€å€‹ä»‹æ–¼ Z1 èˆ‡ Z2 ä¹‹é–“çš„æ–°æ•¸æ“šé» Zmid ï¼Œé€™æ™‚å€™å‚³çµ±è‡ªç·¨ç¢¼å™¨å¯èƒ½æœƒé‡åˆ°å•é¡Œã€‚
        ç”±æ–¼æ½›åœ¨ç©ºé–“ä¸­å¯èƒ½å­˜åœ¨ã€Œç©ºæ´ã€æˆ–ä¸é€£çºŒçš„å€åŸŸï¼ŒZmid å°æ‡‰çš„è§£ç¢¼çµæœå¯èƒ½å®Œå…¨ç„¡æ³•ä»£è¡¨çœŸå¯¦çš„æ•¸æ“šã€‚
        é€™æ˜¯å› ç‚ºå‚³çµ±è‡ªç·¨ç¢¼å™¨æ²’æœ‰æ˜ç¢ºæ§åˆ¶æ½›åœ¨ç©ºé–“çš„çµæ§‹ï¼Œå°è‡´æ’å€¼å‡ºä¾†çš„é»ä¸ä¸€å®šæœ‰æ„ç¾©ã€‚

        
        ã€è¨»ã€‘ï¼šéš¨æ©Ÿé‡‡æ¨£çš„å•é¡Œ
        éš¨æ©Ÿé‡‡æ¨£æŒ‡çš„æ˜¯åœ¨æ½›åœ¨ç©ºé–“ä¸­éš¨æ©Ÿé¸æ“‡ä¸€å€‹é»ä¾†ç”Ÿæˆæ•¸æ“šã€‚
        å‚³çµ±è‡ªç·¨ç¢¼å™¨çš„æ½›åœ¨ç©ºé–“æ²’æœ‰ç¶“éç‰¹æ®Šè¨­è¨ˆæˆ–æ­£å‰‡åŒ–ï¼Œå› æ­¤é€™å€‹ç©ºé–“å¯èƒ½éå¸¸ä¸è¦å‰‡ã€‚å¦‚æœæˆ‘å€‘éš¨æ©Ÿå¾æ½›åœ¨ç©ºé–“ä¸­é¸æ“‡ä¸€å€‹é»ï¼Œé€™å€‹é»å¾ˆå¯èƒ½ä½æ–¼â€œç©ºæ´â€å€åŸŸï¼Œå³ä¸ä»£è¡¨ä»»ä½•çœŸå¯¦æ•¸æ“šçš„å€åŸŸã€‚é€™æ¨£è§£ç¢¼å‡ºä¾†çš„çµæœä¹Ÿå¯èƒ½æ˜¯ç„¡æ„ç¾©æˆ–å¤±çœŸçš„ã€‚

        
VAE çš„ä¸»è¦å„ªå‹¢åœ¨æ–¼å®ƒèƒ½å¤ åŒæ™‚é€²è¡Œç”Ÿæˆå’Œæ¨æ–·ï¼Œä¸¦ä¸”èƒ½å¤ åœ¨æ½›åœ¨ç©ºé–“ä¸­é€²è¡Œæœ‰æ•ˆçš„éš¨æ©Ÿé‡‡æ¨£ã€‚
    VAE å°‡è¼¸å…¥æ•¸æ“šæ˜ å°„åˆ°ä¸€çµ„æ¦‚ç‡åˆ†ä½ˆåƒæ•¸(å‡å€¼å’Œæ–¹å·®)ï¼Œè€Œä¸æ˜¯ç¢ºå®šæ€§çš„æ½›åœ¨å‘é‡ã€‚
    VAE çš„ç·¨ç¢¼å™¨å°‡è¼¸å…¥æ•¸æ“š x æ˜ å°„åˆ°ä¸€å€‹é«˜æ–¯åˆ†ä½ˆçš„åƒæ•¸ï¼š å‡å€¼(ğœ‡) å’Œ å°æ•¸æ–¹å·®(log(Ïƒ**2))

    å°æ–¼æ¯ä¸€å€‹è¼¸å…¥æ•¸æ“šï¼Œç·¨ç¢¼å™¨æœƒè¼¸å‡ºä¸€å€‹é«˜æ–¯åˆ†ä½ˆï¼Œé€™å€‹åˆ†ä½ˆç”¨ä¾†è¡¨ç¤ºå¯èƒ½çš„æ½›åœ¨ç©ºé–“è¡¨ç¤ºã€‚
    é€™æ„å‘³è‘—ï¼Œæ¯æ¬¡é‡‡æ¨£å‡ºçš„æ–°æ•¸æ“šéƒ½æœƒç•¥æœ‰ä¸åŒï¼Œé€™å°±å¼•å…¥äº†éš¨æ©Ÿæ€§ï¼Œä½¿å¾—ç”Ÿæˆçš„æ•¸æ“šå…·æœ‰æ›´å¤šçš„å¤šæ¨£æ€§ã€‚

    
VAE é‹ä½œé‚è¼¯
    1. ç·¨ç¢¼ï¼šè¼¸å…¥æ•¸æ“š x ç¶“éç·¨ç¢¼å™¨ï¼Œå¾—åˆ°ä¸€çµ„å‡å€¼å’Œæ–¹å·®åƒæ•¸ (ğœ‡,log(Ïƒ**2))
    2. æ½›åœ¨è®Šé‡é‡‡æ¨£ï¼šå¾é«˜æ–¯åˆ†ä½ˆä¸­é‡‡æ¨£å¾—åˆ°æ½›åœ¨è®Šé‡ z
    3. è§£ç¢¼ï¼šå°‡ z å…¥è§£ç¢¼å™¨ï¼Œç”Ÿæˆèˆ‡åŸå§‹æ•¸æ“šç›¸ä¼¼çš„æ•¸æ“š x'
    4. æå¤±è¨ˆç®—ï¼šè¨ˆç®—é‡å»ºèª¤å·®å’Œ ã€KLæ•£åº¦ã€‘ï¼Œä¸¦æœ€å°åŒ–ç¸½æå¤±
     
        ã€è¨»ã€‘ï¼šKL æ•£åº¦
        Kullback-Leibler æ•£åº¦ (KL æ•£åº¦)ï¼Œä¹Ÿç¨±ç‚ºç›¸å°ç†µ(Relative Entropy)ã€‚
        æ˜¯ä¿¡æ¯ç†è«–ä¸­çš„ä¸€å€‹é‡è¦æ¦‚å¿µï¼Œç”¨ä¾†è¡¡é‡å…©å€‹æ¦‚ç‡åˆ†ä½ˆä¹‹é–“çš„å·®ç•°ç¨‹åº¦ã€‚è¡¡é‡çš„æ˜¯ç•¶ä½¿ç”¨ä¸€å€‹åˆ†ä½ˆä¾†è¿‘ä¼¼å¦ä¸€å€‹åˆ†ä½ˆæ™‚ï¼Œæœƒæå¤±å¤šå°‘ä¿¡æ¯ã€‚

'''


import matplotlib.pyplot as plt
import numpy as np 
import pandas as pd 
import random 
import os 

import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader,random_split
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.manifold import TSNE # ç”¨æ–¼é«˜ç¶­åº¦æ•¸æ“šçš„å¯è¦–åŒ–ã€‚t-SNEæ˜¯ä¸€ç¨®éç·šæ€§é™ç¶­æŠ€è¡“ã€‚

PATH_DATASETS = "" # é è¨­è·¯å¾‘
BATCH_SIZE = 256  # æ‰¹é‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
"cuda" if torch.cuda.is_available() else "cpu"

train_ds = torchvision.datasets.MNIST(PATH_DATASETS, train=True, download=True)
test_ds  = torchvision.datasets.MNIST(PATH_DATASETS, train=False, download=True)

# å»ºç«‹ä¸€å€‹åœ–åƒç¶²æ ¼ï¼Œç”¨æ–¼é¡¯ç¤ºæ•¸æ“šé›†ä¸­çš„åœ–ç‰‡
fig, axs = plt.subplots(4, 5, figsize=(8,8))
# ç”Ÿæˆä¸€å€‹4x5çš„å­åœ–ï¼Œæ¯å€‹å­åœ–å¤§å°ç‚º8x8è‹±å¯¸

for ax in axs.flatten(): # å°‡å¤šç¶­çš„å­åœ–é™£åˆ—å±•å¹³ï¼Œæ–¹ä¾¿è¿­ä»£
    # éš¨æ©ŸæŠ½æ¨£
    img, label = random.choice(train_ds) # éš¨æ©ŸæŠ½æ¨£ä¸€å¼µåœ–åƒå’Œå…¶å°æ‡‰çš„æ¨™ç±¤
    ax.imshow(np.array(img), cmap='gist_gray')
    # å°‡åœ–åƒè½‰æ›ç‚ºnumpyæ•¸çµ„ä¸¦ä½¿ç”¨ç°åº¦é¡è‰²é¡¯ç¤º
    ax.set_title('Label: %d' % label)  # è¨­ç½®åœ–åƒæ¨™é¡Œç‚ºå…¶æ¨™ç±¤
    ax.set_xticks([])
    ax.set_yticks([]) # ç§»é™¤xè»¸å’Œyè»¸çš„åˆ»åº¦
plt.tight_layout() # è‡ªå‹•èª¿æ•´å­åœ–åƒæ•¸ï¼Œä½¿åœ–åƒä¸é‡ç–Š

# è½‰ç‚ºå¼µé‡
train_ds.transform = transforms.ToTensor() # è½‰æ›ç‚ºTENSOR
test_ds.transform = transforms.ToTensor() 

# åˆ‡å‰²20%è¨“ç·´è³‡æ–™ä½œç‚ºé©—è­‰è³‡æ–™
m=len(train_ds) # ç¸½ç­†æ•¸

# ä½¿ç”¨random_splitå°‡è¨“ç·´æ•¸æ“šé›†åˆ†å‰²ç‚ºè¨“ç·´é›†å’Œé©—è­‰é›†ï¼Œ80%ä½œç‚ºè¨“ç·´é›†ï¼Œ20%ä½œç‚ºé©—è­‰é›†
train_data, val_data = random_split(train_ds, [int(m-m*0.2), int(m*0.2)])

# å‰µå»ºè¨“ç·´æ•¸æ“šé›†çš„DataLoaderï¼Œæ¯æ¬¡åŠ è¼‰BATCH_SIZEå€‹æ¨£æœ¬
train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE)
# å‰µå»ºé©—è­‰æ•¸æ“šé›†çš„DataLoaderï¼Œæ¯æ¬¡åŠ è¼‰BATCH_SIZEå€‹æ¨£æœ¬
valid_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE)
# å‰µå»ºæ¸¬è©¦æ•¸æ“šé›†çš„DataLoaderï¼Œæ¯æ¬¡åŠ è¼‰BATCH_SIZEå€‹æ¨£æœ¬ï¼Œä¸¦éš¨æ©Ÿæ‰“äº‚æ•¸æ“šé †åº
test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE,shuffle=True)

class Encoder(nn.Module):
    def __init__(self, encoded_space_dim,fc2_input_dim):
        super().__init__()
        
        # Convolution
        self.encoder_cnn = nn.Sequential(
            nn.Conv2d(1, 8, 3, stride=2, padding=1), # ç¬¬1å€‹å·ç©å±¤ï¼šè¼¸å…¥é€šé“1ï¼Œè¼¸å‡ºé€šé“8ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œå¡«å……1
            nn.ReLU(True), # æ¿€æ´»å‡½æ•¸ï¼šReLU
            nn.Conv2d(8, 16, 3, stride=2, padding=1), # ç¬¬2å€‹å·ç©å±¤ï¼šè¼¸å…¥é€šé“8ï¼Œè¼¸å‡ºé€šé“16ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œå¡«å……1
            nn.BatchNorm2d(16), # æ‰¹é‡æ­¸ä¸€åŒ–
            nn.ReLU(True), # æ¿€æ´»å‡½æ•¸ï¼šReLUï¼Œinplace=Trueç¯€çœå…§å­˜
            nn.Conv2d(16, 32, 3, stride=2, padding=0),  # ç¬¬3å€‹å·ç©å±¤ï¼šè¼¸å…¥é€šé“16ï¼Œè¼¸å‡ºé€šé“32ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œç„¡å¡«å……
            nn.ReLU(True)
        )
        
        self.flatten = nn.Flatten(start_dim=1) # å°‡å¤šç¶­è¼¸å…¥å±•å¹³ç‚ºä¸€ç¶­ï¼Œå¾ç¬¬1ç¶­é–‹å§‹å±•å¹³

        self.encoder_lin = nn.Sequential(
            nn.Linear(3 * 3 * 32, 128), # å…¨é€£æ¥å±¤ï¼šè¼¸å…¥å°ºå¯¸3*3*32ï¼Œè¼¸å‡ºå°ºå¯¸128
        )
        
        self.encFC1 = nn.Linear(128, encoded_space_dim)  # ç·¨ç¢¼å™¨å…¨é€£æ¥å±¤1ï¼šè¼¸å‡ºencoded_space_dimç¶­åº¦
        self.encFC2 = nn.Linear(128, encoded_space_dim)  # ç·¨ç¢¼å™¨å…¨é€£æ¥å±¤2ï¼šè¼¸å‡ºencoded_space_dimç¶­åº¦
        
    def forward(self, x):  # å‰å‘å‚³æ’­å‡½æ•¸ï¼Œå®šç¾©è¼¸å…¥æ•¸æ“šå¦‚ä½•ç¶“éç·¨ç¢¼å™¨ç¶²çµ¡
        x = self.encoder_cnn(x)  # è¼¸å…¥ç¶“éå·ç©å±¤
        x = self.flatten(x)  # å±•å¹³è¼¸å‡º
        x = self.encoder_lin(x)  # è¼¸å…¥ç¶“éå…¨é€£æ¥å±¤
        mu = self.encFC1(x)  # è¨ˆç®—å‡å€¼
        logVar = self.encFC2(x)  # è¨ˆç®—å°æ•¸æ–¹å·®
        return mu, logVar  # è¿”å›å‡å€¼å’Œå°æ•¸æ–¹å·®

def resample(mu, logVar):  # é‡åƒæ•¸åŒ–å‡½æ•¸ï¼Œä½¿ç”¨å‡å€¼å’Œå°æ•¸æ–¹å·®é€²è¡Œé‡æ–°æ¡æ¨£
    std = torch.exp(logVar / 2)  # è¨ˆç®—æ¨™æº–å·®
    eps = torch.randn_like(std)  # ç”Ÿæˆèˆ‡æ¨™æº–å·®å½¢ç‹€ç›¸åŒçš„æ¨™æº–æ­£æ…‹åˆ†ä½ˆå™ªè²
    return mu + std * eps  # è¿”å›é‡æ–°æ¡æ¨£çš„çµæœ

class Decoder(nn.Module):  # å®šç¾©è§£ç¢¼å™¨æ¨¡å‹é¡
    def __init__(self, encoded_space_dim, fc2_input_dim):  # åˆå§‹åŒ–å‡½æ•¸ï¼Œè¨­å®šç·¨ç¢¼ç©ºé–“ç¶­åº¦å’Œå…¨é€£æ¥å±¤è¼¸å…¥ç¶­åº¦
        super().__init__()

        self.decoder_lin = nn.Sequential(  # å®šç¾©ä¸€ç³»åˆ—å…¨é€£æ¥å±¤
            nn.Linear(encoded_space_dim, 128),  # å…¨é€£æ¥å±¤ï¼šè¼¸å…¥encoded_space_dimç¶­åº¦ï¼Œè¼¸å‡º128ç¶­åº¦
            nn.ReLU(True),  # æ¿€æ´»å‡½æ•¸ï¼šReLUï¼Œinplace=Trueç¯€çœå…§å­˜
            nn.Linear(128, 3 * 3 * 32),  # å…¨é€£æ¥å±¤ï¼šè¼¸å…¥128ç¶­åº¦ï¼Œè¼¸å‡º3*3*32ç¶­åº¦
            nn.ReLU(True)  # æ¿€æ´»å‡½æ•¸ï¼šReLUï¼Œinplace=Trueç¯€çœå…§å­˜
        )

        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))  # å°‡ä¸€ç¶­æ•¸æ“šé‡æ§‹ç‚ºå¤šç¶­å¼µé‡

        self.decoder_conv = nn.Sequential(  # å®šç¾©ä¸€ç³»åˆ—åå·ç©å±¤
            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),  # ç¬¬1å€‹åå·ç©å±¤ï¼šè¼¸å…¥é€šé“32ï¼Œè¼¸å‡ºé€šé“16ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œç„¡é¡å¤–å¡«å……
            nn.BatchNorm2d(16),  # æ‰¹é‡æ­¸ä¸€åŒ–ï¼Œå°16å€‹é€šé“é€²è¡Œæ¨™æº–åŒ–
            nn.ReLU(True),  # æ¿€æ´»å‡½æ•¸ï¼šReLUï¼Œinplace=Trueç¯€çœå…§å­˜
            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),  # ç¬¬2å€‹åå·ç©å±¤ï¼šè¼¸å…¥é€šé“16ï¼Œè¼¸å‡ºé€šé“8ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œå¡«å……1ï¼Œè¼¸å‡ºå¡«å……1
            nn.BatchNorm2d(8),  # æ‰¹é‡æ­¸ä¸€åŒ–ï¼Œå°8å€‹é€šé“é€²è¡Œæ¨™æº–åŒ–
            nn.ReLU(True),  # æ¿€æ´»å‡½æ•¸ï¼šReLUï¼Œinplace=Trueç¯€çœå…§å­˜
            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)  # ç¬¬3å€‹åå·ç©å±¤ï¼šè¼¸å…¥é€šé“8ï¼Œè¼¸å‡ºé€šé“1ï¼Œå·ç©æ ¸å¤§å°3x3ï¼Œæ­¥é•·2ï¼Œå¡«å……1ï¼Œè¼¸å‡ºå¡«å……1
        )
        
    def forward(self, x):
        x = self.decoder_lin(x)  # é€šéå…¨é€£æ¥å±¤é€²è¡Œç·šæ€§è®Šæ›
        x = self.unflatten(x)  # å°‡ä¸€ç¶­å¼µé‡é‡æ§‹ç‚ºå¤šç¶­å¼µé‡ï¼Œæº–å‚™é€²è¡Œå·ç©æ“ä½œ
        x = self.decoder_conv(x)  # é€šéä¸€ç³»åˆ—åå·ç©å±¤é€²è¡Œä¸Šæ¡æ¨£
        x = torch.sigmoid(x)  # ä½¿ç”¨Sigmoidæ¿€æ´»å‡½æ•¸å°‡è¼¸å‡ºæ˜ å°„åˆ°0åˆ°1ä¹‹é–“
        return x  # è¿”å›é‡å»ºå¾Œçš„åœ–åƒå¼µé‡

# å›ºå®šéš¨æ©Ÿäº‚æ•¸ç¨®å­ï¼Œä»¥åˆ©æŒæ¡åŸ·è¡Œçµæœ
torch.manual_seed(0)  # è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœçš„å¯é‡ç¾æ€§

# encoder è¼¸å‡ºå€‹æ•¸ã€decoder è¼¸å…¥å€‹æ•¸
d = 4  # è¨­å®šç·¨ç¢¼å™¨çš„è¼¸å‡ºç¶­åº¦å’Œè§£ç¢¼å™¨çš„è¼¸å…¥ç¶­åº¦
encoder = Encoder(encoded_space_dim=d, fc2_input_dim=128).to(device)  # åˆå§‹åŒ–ä¸¦å°‡ç·¨ç¢¼å™¨æ¨¡å‹åŠ è¼‰åˆ°è¨­å‚™ä¸Š
decoder = Decoder(encoded_space_dim=d, fc2_input_dim=128).to(device)  # åˆå§‹åŒ–ä¸¦å°‡è§£ç¢¼å™¨æ¨¡å‹åŠ è¼‰åˆ°è¨­å‚™ä¸Š

# KL divergence
def loss_fn(out, imgs, mu, logVar):
    kl_divergence = 0.5 * torch.sum(1 + logVar - mu.pow(2) - logVar.exp())  # è¨ˆç®—KLæ•£åº¦ï¼Œç”¨æ–¼è¡¡é‡è¼¸å‡ºçš„åˆ†ä½ˆèˆ‡æ¨™æº–æ­£æ…‹åˆ†ä½ˆä¹‹é–“çš„å·®ç•°
    return F.binary_cross_entropy(out, imgs, size_average=False) - kl_divergence  # è¨ˆç®—ç¸½æå¤±ï¼ŒåŒ…æ‹¬é‡æ§‹èª¤å·®å’ŒKLæ•£åº¦

lr = 0.001  # Learning rate è¨­ç½®å­¸ç¿’ç‡

params_to_optimize = [
    {'params': encoder.parameters()},  # ç·¨ç¢¼å™¨çš„åƒæ•¸
    {'params': decoder.parameters()}  # è§£ç¢¼å™¨çš„åƒæ•¸
]

optim = torch.optim.Adam(params_to_optimize, lr=lr)  # ä½¿ç”¨Adamå„ªåŒ–å™¨ï¼Œä¸¦è¨­ç½®å­¸ç¿’ç‡

def add_noise(inputs, noise_factor=0.3):
    noise = inputs + torch.randn_like(inputs) * noise_factor  # åœ¨è¼¸å…¥åœ–åƒä¸Šæ·»åŠ é«˜æ–¯å™ªè²
    noise = torch.clip(noise, 0., 1.)  # å°‡å™ªè²è™•ç†å¾Œçš„åœ–åƒå€¼é™åˆ¶åœ¨0åˆ°1ä¹‹é–“
    return noise  # è¿”å›åŠ äº†å™ªè²çš„åœ–åƒ

def train_epoch_den(encoder, decoder, device, dataloader, 
                    loss_fn, optimizer, noise_factor=0.3):
    encoder.train()  # è¨­ç½®ç·¨ç¢¼å™¨ç‚ºè¨“ç·´æ¨¡å¼
    decoder.train()  # è¨­ç½®è§£ç¢¼å™¨ç‚ºè¨“ç·´æ¨¡å¼
    train_loss = []  # ç”¨æ–¼ä¿å­˜æ¯å€‹batchçš„æå¤±å€¼

    for image_batch, _ in dataloader:  # å¾æ•¸æ“šåŠ è¼‰å™¨ä¸­è¿­ä»£åœ–åƒæ‰¹æ¬¡
        image_noisy = add_noise(image_batch, noise_factor)  # ç‚ºæ¯å€‹æ‰¹æ¬¡åœ–åƒæ·»åŠ å™ªè²
        image_noisy = image_noisy.to(device)  # å°‡åŠ äº†å™ªè²çš„åœ–åƒç§»åˆ°è¨­å‚™ä¸Š
        mu, logVar = encoder(image_noisy)  # é€šéç·¨ç¢¼å™¨è¼¸å‡ºå‡å€¼å’Œå°æ•¸æ–¹å·®
        encoded_data = resample(mu, logVar)  # æ ¹æ“šå‡å€¼å’Œå°æ•¸æ–¹å·®é€²è¡Œé‡æ–°æ¡æ¨£
        decoded_data = decoder(encoded_data)  # é€šéè§£ç¢¼å™¨é‡å»ºåœ–åƒ
        loss = loss_fn(decoded_data, image_noisy, mu, logVar)  # è¨ˆç®—æå¤±å€¼

        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        loss.backward()  # åå‘å‚³æ’­è¨ˆç®—æ¢¯åº¦
        optimizer.step()  # æ›´æ–°åƒæ•¸
        train_loss.append(loss.detach().cpu().numpy())  # å°‡ç•¶å‰æ‰¹æ¬¡çš„æå¤±å€¼ä¿å­˜

    return np.mean(train_loss)  # è¿”å›ç•¶å‰epochçš„å¹³å‡æå¤±å€¼


def train_epoch_den(encoder, decoder, device, dataloader, loss_fn, optimizer, noise_factor=0.3):
    encoder.train()  # å°‡ç·¨ç¢¼å™¨è¨­å®šç‚ºè¨“ç·´æ¨¡å¼
    decoder.train()  # å°‡è§£ç¢¼å™¨è¨­å®šç‚ºè¨“ç·´æ¨¡å¼
    train_loss = []  # ç”¨æ–¼ä¿å­˜æ¯å€‹batchçš„æå¤±å€¼

    for image_batch, _ in dataloader:  # å¾æ•¸æ“šåŠ è¼‰å™¨ä¸­è¿­ä»£ç²å–åœ–åƒæ‰¹æ¬¡
        image_noisy = add_noise(image_batch, noise_factor)  # ç‚ºåœ–åƒæ‰¹æ¬¡æ·»åŠ å™ªè²
        image_noisy = image_noisy.to(device)  # å°‡åŠ äº†å™ªè²çš„åœ–åƒç§»åˆ°è¨­å‚™ä¸Š
        mu, logVar = encoder(image_noisy)  # é€šéç·¨ç¢¼å™¨è¼¸å‡ºå‡å€¼å’Œå°æ•¸æ–¹å·®
        encoded_data = resample(mu, logVar)  # æ ¹æ“šå‡å€¼å’Œå°æ•¸æ–¹å·®é€²è¡Œé‡æ–°æ¡æ¨£
        decoded_data = decoder(encoded_data)  # é€šéè§£ç¢¼å™¨é‡å»ºåœ–åƒ
        loss = loss_fn(decoded_data, image_noisy, mu, logVar)  # è¨ˆç®—æå¤±å€¼

        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        loss.backward()  # åå‘å‚³æ’­è¨ˆç®—æ¢¯åº¦
        optimizer.step()  # æ›´æ–°åƒæ•¸
        train_loss.append(loss.detach().cpu().numpy())  # ä¿å­˜ç•¶å‰æ‰¹æ¬¡çš„æå¤±å€¼

    return np.mean(train_loss)  # è¿”å›ç•¶å‰epochçš„å¹³å‡æå¤±å€¼


def test_epoch_den(encoder, decoder, device, dataloader, loss_fn, noise_factor=0.3):
    encoder.eval()  # å°‡ç·¨ç¢¼å™¨è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
    decoder.eval()  # å°‡è§£ç¢¼å™¨è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
    val_loss = 0.0  # åˆå§‹åŒ–é©—è­‰æå¤±ç‚º0
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è¨ˆç®—ï¼Œä»¥æé«˜æ¨ç†é€Ÿåº¦ä¸¦ç¯€çœå…§å­˜
        conc_out = []  # ç”¨æ–¼ä¿å­˜æ‰€æœ‰æ‰¹æ¬¡çš„è§£ç¢¼è¼¸å‡º
        conc_label = []  # ç”¨æ–¼ä¿å­˜æ‰€æœ‰æ‰¹æ¬¡çš„åŸå§‹æ¨™ç±¤
        for image_batch, _ in dataloader:  # å¾æ•¸æ“šåŠ è¼‰å™¨ä¸­è¿­ä»£ç²å–åœ–åƒæ‰¹æ¬¡
            image_noisy = add_noise(image_batch, noise_factor)  # ç‚ºåœ–åƒæ‰¹æ¬¡æ·»åŠ å™ªè²
            image_noisy = image_noisy.to(device)  # å°‡åŠ äº†å™ªè²çš„åœ–åƒç§»åˆ°è¨­å‚™ä¸Š
            mu, logVar = encoder(image_noisy)  # é€šéç·¨ç¢¼å™¨è¼¸å‡ºå‡å€¼å’Œå°æ•¸æ–¹å·®
            encoded_data = resample(mu, logVar)  # æ ¹æ“šå‡å€¼å’Œå°æ•¸æ–¹å·®é€²è¡Œé‡æ–°æ¡æ¨£
            decoded_data = decoder(encoded_data)  # é€šéè§£ç¢¼å™¨é‡å»ºåœ–åƒ
            conc_out.append(decoded_data.cpu())  # å°‡è§£ç¢¼è¼¸å‡ºç§»åˆ°CPUä¸¦ä¿å­˜
            conc_label.append(image_batch.cpu())  # å°‡åŸå§‹åœ–åƒç§»åˆ°CPUä¸¦ä¿å­˜
            val_loss += loss_fn(decoded_data.cpu(), image_batch.cpu(), mu, logVar)  # ç´¯åŠ æ¯å€‹æ‰¹æ¬¡çš„æå¤±å€¼

        conc_out = torch.cat(conc_out)  # å°‡æ‰€æœ‰æ‰¹æ¬¡çš„è§£ç¢¼è¼¸å‡ºæ‹¼æ¥æˆä¸€å€‹å¼µé‡
        conc_label = torch.cat(conc_label)  # å°‡æ‰€æœ‰æ‰¹æ¬¡çš„åŸå§‹æ¨™ç±¤æ‹¼æ¥æˆä¸€å€‹å¼µé‡

    return val_loss.data  # è¿”å›é©—è­‰æå¤±å€¼



# è¨­å®šMatplotlibä½¿ç”¨å¾®è»Ÿæ­£é»‘é«”ï¼Œä¸¦ä¿®æ­£è² è™Ÿé¡¯ç¤ºå•é¡Œ
from matplotlib.font_manager import FontProperties
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']  # è¨­å®šå­—é«”ç‚ºå¾®è»Ÿæ­£é»‘é«”
plt.rcParams['axes.unicode_minus'] = False  # ç¢ºä¿è² è™Ÿå¯ä»¥æ­£ç¢ºé¡¯ç¤º

def plot_ae_outputs_den(epoch, encoder, decoder, n=5, noise_factor=0.3):
    plt.figure(figsize=(10, 4.5))  # å‰µå»ºä¸€å€‹æ–°çš„åœ–å½¢ï¼Œå¤§å°ç‚º10x4.5è‹±å¯¸

    for i in range(n):  # è¿­ä»£næ¬¡ï¼Œç”Ÿæˆnå€‹å­åœ–
        ax = plt.subplot(3, n, i + 1)  # å‰µå»ºå­åœ–ï¼Œ3è¡Œnåˆ—ï¼Œç•¶å‰æ˜¯ç¬¬i+1å€‹å­åœ–
        img = test_ds[i][0].unsqueeze(0)  # å¾æ¸¬è©¦æ•¸æ“šé›†ä¸­ç²å–ç¬¬iå€‹åœ–åƒï¼Œä¸¦æ·»åŠ ä¸€å€‹ç¶­åº¦(æ‰¹æ¬¡å¤§å°ç‚º1)
        image_noisy = add_noise(img, noise_factor)  # ç‚ºåœ–åƒæ·»åŠ å™ªè²
        image_noisy = image_noisy.to(device)  # å°‡åŠ äº†å™ªè²çš„åœ–åƒç§»åˆ°è¨­å‚™ä¸Š

        encoder.eval()  # å°‡ç·¨ç¢¼å™¨è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
        decoder.eval()  # å°‡è§£ç¢¼å™¨è¨­å®šç‚ºè©•ä¼°æ¨¡å¼

        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è¨ˆç®—ï¼Œä»¥æé«˜æ¨ç†é€Ÿåº¦ä¸¦ç¯€çœå…§å­˜
            rec_img = decoder(resample(*encoder(image_noisy)))  # å°‡å™ªè²åœ–åƒç¶“éç·¨ç¢¼å™¨å’Œè§£ç¢¼å™¨ç”Ÿæˆé‡å»ºåœ–åƒ

        if epoch == 0:  # å¦‚æœæ˜¯ç¬¬0å€‹epochï¼Œç¹ªè£½åŸåœ–å’ŒåŠ äº†å™ªè²çš„åœ–åƒ
            plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')  # é¡¯ç¤ºåŸåœ–åƒ
            ax.get_xaxis().set_visible(False)  # éš±è—xè»¸
            ax.get_yaxis().set_visible(False)  # éš±è—yè»¸  
            if i == n // 2:  # åœ¨ç¬¬n//2å€‹å­åœ–ä¸Šè¨­ç½®æ¨™é¡Œ
                ax.set_title('åŸåœ–')

            ax = plt.subplot(3, n, i + 1 + n)  # å‰µå»ºä¸‹ä¸€è¡Œçš„å­åœ–
            plt.imshow(image_noisy.cpu().squeeze().numpy(), cmap='gist_gray')  # é¡¯ç¤ºåŠ äº†å™ªè²çš„åœ–åƒ
            ax.get_xaxis().set_visible(False)  # éš±è—xè»¸
            ax.get_yaxis().set_visible(False)  # éš±è—yè»¸  
            if i == n // 2:  # åœ¨ç¬¬n//2å€‹å­åœ–ä¸Šè¨­ç½®æ¨™é¡Œ
                ax.set_title('åŠ é›œè¨Š')

        if epoch == 0:  # å¦‚æœæ˜¯ç¬¬0å€‹epoch
            ax = plt.subplot(3, n, i + 1 + n + n)  # å‰µå»ºç¬¬ä¸‰è¡Œçš„å­åœ–ï¼Œé¡¯ç¤ºé‡å»ºåœ–åƒ
        else:
            ax = plt.subplot(1, n, i + 1)  # å¦å‰‡ç›´æ¥åœ¨ç¬¬ä¸€è¡Œé¡¯ç¤ºé‡å»ºåœ–åƒ
        plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  # é¡¯ç¤ºé‡å»ºå¾Œçš„åœ–åƒ
        ax.get_xaxis().set_visible(False)  # éš±è—xè»¸
        ax.get_yaxis().set_visible(False)  # éš±è—yè»¸  
        if epoch == 0 and i == n // 2:  # åœ¨ç¬¬0å€‹epochçš„ç¬¬n//2å€‹å­åœ–ä¸Šè¨­ç½®æ¨™é¡Œ
            ax.set_title('é‡å»ºåœ–åƒ')

    # èª¿æ•´å­åœ–ä¹‹é–“çš„é–“è·
    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.7, top=0.9, wspace=0.3, hspace=0.3)  
    plt.show()  # é¡¯ç¤ºåœ–å½¢


noise_factor = 0.3  # è¨­ç½®å™ªè²å› å­ï¼Œç”¨æ–¼å‘åœ–åƒæ·»åŠ å™ªè²
num_epochs = 50  # è¨“ç·´çš„ç¸½epochæ•¸
history_da = {'train_loss': [], 'val_loss': []}  # åˆå§‹åŒ–å­—å…¸ï¼Œç”¨æ–¼ä¿å­˜æ¯å€‹epochçš„è¨“ç·´å’Œé©—è­‰æå¤±

for epoch in range(num_epochs):  # è¿­ä»£é€²è¡Œæ¯å€‹epochçš„è¨“ç·´å’Œé©—è­‰
    # è¨“ç·´æ¨¡å‹
    train_loss = train_epoch_den(
        encoder=encoder, 
        decoder=decoder, 
        device=device, 
        dataloader=train_loader, 
        loss_fn=loss_fn, 
        optimizer=optim,
        noise_factor=noise_factor
    )

    # é©—è­‰æ¨¡å‹
    val_loss = test_epoch_den(
        encoder=encoder, 
        decoder=decoder, 
        device=device, 
        dataloader=valid_loader, 
        loss_fn=loss_fn,
        noise_factor=noise_factor
    )

    # ä¿å­˜æ¯å€‹epochçš„è¨“ç·´å’Œé©—è­‰æå¤±
    history_da['train_loss'].append(train_loss)
    history_da['val_loss'].append(val_loss)

    # æ‰“å°ç•¶å‰epochçš„è¨“ç·´å’Œé©—è­‰æå¤±
    print(f'EPOCH {epoch + 1}/{num_epochs} \t è¨“ç·´æå¤±ï¼š{train_loss:.3f}' + 
          f' \t é©—è­‰æå¤±ï¼š {val_loss:.3f}')
    
    # ç¹ªè£½ç•¶å‰epochçš„é‡å»ºåœ–åƒã€åŸå§‹åœ–åƒã€åŠ å™ªè²åœ–åƒ
    plot_ae_outputs_den(epoch, encoder, decoder, noise_factor=noise_factor)

# åœ¨æ¸¬è©¦é›†ä¸Šé€²è¡Œæœ€çµ‚çš„é©—è­‰ï¼Œä¸¦è¿”å›æå¤±å€¼
test_epoch_den(encoder, decoder, device, test_loader, loss_fn).item()

def plot_reconstructed(decoder, r0=(-5, 10), r1=(-10, 5), n=10):
    plt.figure(figsize=(20, 8.5))  # å‰µå»ºåœ–å½¢ï¼Œå¤§å°ç‚º20x8.5è‹±å¯¸
    w = 28  # æ¯å€‹å°åœ–åƒçš„å¯¬åº¦(åƒç´ )
    img = np.zeros((n * w, n * w))  # åˆå§‹åŒ–å¤§åœ–åƒï¼Œå°ºå¯¸ç‚ºn*w x n*w

    # éæ­·æ¯å€‹ä½ç½®ï¼Œç”Ÿæˆä¸¦ç¹ªè£½è§£ç¢¼å™¨é‡å»ºçš„åœ–åƒ
    for i, y in enumerate(np.linspace(*r1, n)):
        for j, x in enumerate(np.linspace(*r0, n)):
            z = torch.Tensor([[x, y], [x, y]]).reshape(-1, 4).to(device)  # å‰µå»ºæ½›åœ¨è®Šé‡å¼µé‡ï¼Œä¸¦ç§»åˆ°è¨­å‚™ä¸Š
            x_hat = decoder(z)  # ä½¿ç”¨è§£ç¢¼å™¨ç”Ÿæˆé‡å»ºåœ–åƒ
            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()  # å°‡é‡å»ºåœ–åƒè½‰æ›ç‚ºnumpyæ•¸çµ„
            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat  # å°‡é‡å»ºåœ–åƒæ”¾ç½®åœ¨å¤§åœ–åƒçš„ç›¸æ‡‰ä½ç½®

    plt.imshow(img, extent=[*r0, *r1], cmap='gist_gray')  # é¡¯ç¤ºæ•´é«”çš„é‡å»ºåœ–åƒ

# ä½¿ç”¨è¨“ç·´å¥½çš„è§£ç¢¼å™¨é€²è¡Œé‡å»ºåœ–åƒçš„å¯è¦–åŒ–
plot_reconstructed(decoder, r0=(-1, 1), r1=(-1, 1))


encoded_samples = []  # åˆå§‹åŒ–ä¸€å€‹ç©ºåˆ—è¡¨ï¼Œç”¨æ–¼ä¿å­˜ç·¨ç¢¼å¾Œçš„æ¨£æœ¬

for sample in test_ds:  # éæ­·æ¸¬è©¦æ•¸æ“šé›†ä¸­çš„æ¯ä¸€å€‹æ¨£æœ¬
    img = sample[0].unsqueeze(0).to(device)  # ç²å–æ¨£æœ¬åœ–åƒï¼Œä¸¦æ·»åŠ ä¸€å€‹ç¶­åº¦(æ‰¹æ¬¡å¤§å°ç‚º1)ï¼Œå°‡å…¶ç§»å‹•åˆ°è¨­å‚™ä¸Š
    label = sample[1]  # ç²å–æ¨£æœ¬çš„æ¨™ç±¤
    encoder.eval()  # å°‡ç·¨ç¢¼å™¨è¨­å®šç‚ºè©•ä¼°æ¨¡å¼
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è¨ˆç®—ï¼Œä»¥æé«˜æ¨ç†é€Ÿåº¦ä¸¦ç¯€çœå…§å­˜
        encoded_img = resample(*encoder(img))  # å°‡åœ–åƒé€šéç·¨ç¢¼å™¨é€²è¡Œç·¨ç¢¼ä¸¦é‡æ–°åƒæ•¸åŒ–ï¼Œç²å¾—ç·¨ç¢¼å¾Œçš„å‘é‡
    encoded_img = encoded_img.flatten().cpu().numpy()  # å°‡ç·¨ç¢¼å‘é‡å±•å¹³ä¸¦è½‰æ›ç‚ºnumpyæ•¸çµ„ï¼Œç§»å‹•åˆ°CPUä¸Š
    encoded_sample = {f"è®Šæ•¸ {i}": enc for i, enc in enumerate(encoded_img)}  # å‰µå»ºä¸€å€‹å­—å…¸ï¼Œå°‡ç·¨ç¢¼å‘é‡çš„æ¯å€‹å…ƒç´ å‘½åç‚º"è®Šæ•¸ i"
    encoded_sample['label'] = label  # åœ¨å­—å…¸ä¸­åŠ å…¥å°æ‡‰çš„æ¨™ç±¤
    encoded_samples.append(encoded_sample)  # å°‡ç·¨ç¢¼å¾Œçš„æ¨£æœ¬åŠ å…¥åˆ—è¡¨

encoded_samples = pd.DataFrame(encoded_samples)  # å°‡åˆ—è¡¨è½‰æ›ç‚ºpandas DataFrame
encoded_samples  # é¡¯ç¤ºç·¨ç¢¼å¾Œçš„æ¨£æœ¬æ•¸æ“šè¡¨æ ¼

import plotly.express as px  # å°å…¥Plotly Expressç”¨æ–¼å¿«é€Ÿç¹ªåœ–
import plotly.graph_objects as go  # å°å…¥Plotly Graph Objectsç”¨æ–¼å‰µå»ºæ›´è¤‡é›œçš„åœ–å½¢

# ä½¿ç”¨Plotlyé€²è¡Œæ•£é»åœ–ç¹ªè£½ï¼Œé¡¯ç¤ºè®Šæ•¸0å’Œè®Šæ•¸1ä¹‹é–“çš„é—œä¿‚ï¼Œé¡è‰²æ ¹æ“šæ¨™ç±¤åˆ†é¡
fig = px.scatter(encoded_samples, x='è®Šæ•¸ 0', y='è®Šæ•¸ 1', 
                 color=encoded_samples.label.astype(str), opacity=0.7)  
fig_widget = go.FigureWidget(fig)  # å°‡Plotlyåœ–å½¢è½‰æ›ç‚ºFigureWidgetä»¥ä¾¿æ–¼é€²è¡Œäº¤äº’å¼é¡¯ç¤º
fig_widget  # é¡¯ç¤ºåœ–å½¢

# ä½¿ç”¨t-SNEé€²è¡Œé™ç¶­ï¼Œå°‡ç·¨ç¢¼å‘é‡å¾é«˜ç¶­åº¦ç©ºé–“é™åˆ°2ç¶­ç©ºé–“
tsne = TSNE(n_components=2)  # åˆå§‹åŒ–t-SNEæ¨¡å‹ï¼Œè¨­ç½®é™ç¶­å¾Œçš„ç¶­åº¦æ•¸ç‚º2
tsne_results = tsne.fit_transform(encoded_samples.drop(['label'], axis=1))  # åŸ·è¡Œt-SNEé™ç¶­ï¼Œä¸¦ä¸Ÿæ£„æ¨™ç±¤åˆ—

# ç¹ªè£½é™ç¶­å¾Œçš„æ•£é»åœ–ï¼Œé¡è‰²æ ¹æ“šæ¨™ç±¤åˆ†é¡
fig = px.scatter(tsne_results, x=0, y=1, color=encoded_samples.label.astype(str),
                 labels={'0': 'tsne-è®Šæ•¸1', '1': 'tsne-è®Šæ•¸2'})  
fig_widget = go.FigureWidget(fig)  # å°‡t-SNEåœ–å½¢è½‰æ›ç‚ºFigureWidgetä»¥ä¾¿æ–¼é€²è¡Œäº¤äº’å¼é¡¯ç¤º
fig_widget  # é¡¯ç¤ºåœ–å½¢


